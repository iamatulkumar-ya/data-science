{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d837e8c",
   "metadata": {},
   "source": [
    "### Word embedding\n",
    "Word embedding, also known as \"word to vector\", is a technique in Natural Language Processing (NLP) that maps words into a continuous vector space where semantically similar words are located close to each other. There are various algorithm that helps to achieve word to vector such as:\n",
    "\n",
    "1. Word2Vec: CBOW and Skip-Gram\n",
    "2. GloVe: Global word co-occurrance \n",
    "3. fastText: extends Word2Vec by considering subword info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936178c",
   "metadata": {},
   "source": [
    "will look into most popular Word2Vec. Word2Vec has two main architecture:\n",
    "\n",
    "1. <b>Continuous Bag-of-Words (CBOW):</b> Predicts the target word based on it's context word. The input layer contains the context words and the output layer contains the current word. The hidden layer contains the dimensions we want to represent the current word present at the output layer. \n",
    "\n",
    "2. <b>Skip-Gram:</b> Predicts contect word within specific window given target word. The input layer contains the current word and the output layer contains the context words. The hidden layer contains the number of dimensions in which we want to represent current word present at the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33125737",
   "metadata": {},
   "source": [
    "Let's load the require libs to implement this. Creating new local environment (.venv_gensim) due to some version conflicts issue with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b099fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1edf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence tokenizer\n",
    "# list of tokenized sentences\n",
    "sentences = [\n",
    "    ['this', 'is', 'a', 'sample', 'sentence'],\n",
    "    ['another', 'sentence', 'for', 'word', 'embeddings'],\n",
    "    ['word', 'embeddings', 'are', 'powerful']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3823a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the Word2Vec model\n",
    "# 'sentences': The corpus to train on.\n",
    "# 'vector_size': Dimension of the word vectors.\n",
    "# 'window': Maximum distance between the current and predicted word within a sentence.\n",
    "# 'min_count': Ignores all words with total frequency lower than this.\n",
    "# 'sg': 0 for CBOW, 1 for Skip-gram.\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# We can also train the model explicitly if you load data incrementally\n",
    "# model.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b221c3",
   "metadata": {},
   "source": [
    "now let's access the vector for a specific word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cb2373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'word': [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
     ]
    }
   ],
   "source": [
    "word_vector = model.wv[\"word\"]\n",
    "print(f\"Vector for 'word': {word_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6dedfc",
   "metadata": {},
   "source": [
    "let's find the similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f07bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'embeddings': [('is', 0.21617142856121063), ('sample', 0.09291722625494003), ('this', 0.06285078823566437), ('a', 0.027057476341724396), ('another', 0.016134677454829216), ('word', -0.01083916611969471), ('are', -0.027750369161367416), ('sentence', -0.05234673246741295), ('for', -0.059876296669244766), ('powerful', -0.111670583486557)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar('embeddings')\n",
    "print(f\"Words similar to 'embeddings': {similar_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9edbfe7",
   "metadata": {},
   "source": [
    "Save and load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"word2vec.model\")\n",
    "# loaded_model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c43aee",
   "metadata": {},
   "source": [
    "https://medium.com/@dilip.voleti/classification-using-word2vec-b1d79d375381"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_gensim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
