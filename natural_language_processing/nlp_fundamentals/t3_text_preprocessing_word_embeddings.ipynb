{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d837e8c",
   "metadata": {},
   "source": [
    "### Word embedding\n",
    "Word embedding, also known as \"word to vector\", is a technique in Natural Language Processing (NLP) that maps words into a continuous vector space where semantically similar words are located close to each other. There are various algorithm that helps to achieve word to vector such as:\n",
    "\n",
    "1. Word2Vec: CBOW and Skip-Gram\n",
    "2. GloVe: Global word co-occurrance \n",
    "3. fastText: extends Word2Vec by considering subword info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936178c",
   "metadata": {},
   "source": [
    "will look into most popular Word2Vec. Word2Vec has two main architecture:\n",
    "\n",
    "1. <b>Continuous Bag-of-Words (CBOW):</b> Predicts the target word based on it's context word. The input layer contains the context words and the output layer contains the current word. The hidden layer contains the dimensions we want to represent the current word present at the output layer. \n",
    "\n",
    "2. <b>Skip-Gram:</b> Predicts contect word within specific window given target word. The input layer contains the current word and the output layer contains the context words. The hidden layer contains the number of dimensions in which we want to represent current word present at the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33125737",
   "metadata": {},
   "source": [
    "Let's load the require libs to implement this. Creating new local environment (.venv_gensim) due to some version conflicts issue with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b099fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e654979",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Natural language processing is the processing of natural language information by a computer. The study of NLP, a subfield of computer science, is generally associated with artificial intelligence. NLP is related to information retrieval, knowledge representation, computational linguistics, and more broadly with linguistics. NLP is used by many applications that use language, such as text translation, voice recognition, text summarization and chatbots. You may have used some of these applications yourself, such as voice-operated GPS systems, digital assistants, speech-to-text software and customer service bots. NLP also helps businesses improve their efficiency, productivity and performance by simplifying complex tasks that involve language.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed1edf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence tokenizer\n",
    "# list of tokenized sentences\n",
    "sentences = [['natural', 'language', 'processing', 'is', 'the', 'processing', 'of', 'natural', 'language', 'information', 'by', 'a', 'computer'],\n",
    "             ['the', 'study', 'of', 'nlp', 'a', 'subfield', 'of', 'computer', 'science', 'is', 'generally', 'associated', 'with', 'artificial', 'intelligence'],\n",
    "             ['nlp', 'is', 'related', 'to', 'information', 'retrieval', 'knowledge', 'representation', 'computational', 'linguistics', 'and', 'more', 'broadly', 'with', 'linguistics'],\n",
    "             ['nlp', 'is', 'used', 'by', 'many', 'applications', 'that', 'use', 'language', 'such', 'as', 'text', 'translation', 'voice', 'recognition', 'text', 'summarization', 'and', 'chatbots'],\n",
    "             ['you', 'may', 'have', 'used', 'some', 'of', 'these', 'applications', 'yourself', 'such', 'as', 'voice-operated', 'gps', 'systems', 'digital', 'assistants', 'speech-to-text', 'software', 'and', 'customer', 'service', 'bots'],\n",
    "             ['nlp', 'also', 'helps', 'businesses', 'improve', 'their', 'efficiency', 'productivity', 'and', 'performance', 'by', 'simplifying', 'complex', 'tasks', 'that', 'involve', 'language']\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3823a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the Word2Vec model\n",
    "# 'sentences': The corpus to train on.\n",
    "# 'vector_size': Dimension of the word vectors.\n",
    "# 'window': Maximum distance between the current and predicted word within a sentence.\n",
    "# 'min_count': Ignores all words with total frequency lower than this.\n",
    "# 'sg': 0 for CBOW, 1 for Skip-gram.\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# We can also train the model explicitly if you load data incrementally\n",
    "# model.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b221c3",
   "metadata": {},
   "source": [
    "now let's access the vector for a specific word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6cb2373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'word': [-5.4003386e-04  2.4686972e-04  5.1032561e-03  9.0068132e-03\n",
      " -9.2969034e-03 -7.1429289e-03  6.4567956e-03  9.0040723e-03\n",
      " -5.0308416e-03 -3.7975647e-03  7.3822839e-03 -1.5640019e-03\n",
      " -4.5311842e-03  6.5645222e-03 -4.8464844e-03 -1.8124769e-03\n",
      "  2.8850122e-03  9.9007005e-04 -8.2795341e-03 -9.4753997e-03\n",
      "  7.3291594e-03  5.0678090e-03  6.7572161e-03  7.6526409e-04\n",
      "  6.3389027e-03 -3.4001863e-03 -9.7024976e-04  5.7662958e-03\n",
      " -7.5205415e-03 -3.9463118e-03 -7.5025591e-03 -9.3113509e-04\n",
      "  9.5465071e-03 -7.3318179e-03 -2.3344674e-03 -1.9194310e-03\n",
      "  8.0814678e-03 -5.9280121e-03  3.4620538e-05 -4.7587682e-03\n",
      " -9.5906006e-03  4.9988711e-03 -8.7502012e-03 -4.3935957e-03\n",
      " -3.0840820e-05 -2.9497084e-04 -7.6713203e-03  9.5948167e-03\n",
      "  4.9820058e-03  9.2406673e-03 -8.1495466e-03  4.4870791e-03\n",
      " -4.1473308e-03  8.2275335e-04  8.5188570e-03 -4.4735475e-03\n",
      "  4.5282380e-03 -6.7842570e-03 -3.5477793e-03  9.4023868e-03\n",
      " -1.5790074e-03  3.2821283e-04 -4.1276081e-03 -7.6685771e-03\n",
      " -1.5157817e-03  2.4830217e-03 -8.8157074e-04  5.5387141e-03\n",
      " -2.7517937e-03  2.2692268e-03  5.4594562e-03  8.3472729e-03\n",
      " -1.4434775e-03 -9.2035765e-03  4.3939753e-03  5.6729693e-04\n",
      "  7.4460884e-03 -8.0483191e-04 -2.6368743e-03 -8.7516103e-03\n",
      " -8.7175955e-04  2.8356921e-03  5.3944346e-03  7.0740199e-03\n",
      " -5.7070991e-03  1.8583363e-03  6.0924697e-03 -4.7920374e-03\n",
      " -3.0932319e-03  6.7951973e-03  1.6457374e-03  1.9021984e-04\n",
      "  3.4737173e-03  2.3100802e-04  9.6330000e-03  5.0670453e-03\n",
      " -8.9287739e-03 -7.0470003e-03  8.9161459e-04  6.4004376e-03]\n"
     ]
    }
   ],
   "source": [
    "word_vector = model.wv[\"language\"]\n",
    "print(f\"Vector for 'word': {word_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6dedfc",
   "metadata": {},
   "source": [
    "let's find the similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f07bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to  language:\n",
      " [('the', 0.21926084160804749), ('applications', 0.21701940894126892), ('many', 0.20485423505306244), ('bots', 0.19553223252296448), ('you', 0.17234398424625397), ('complex', 0.17025862634181976), ('generally', 0.1519763022661209), ('study', 0.14263521134853363), ('voice', 0.14103567600250244), ('systems', 0.14074334502220154)]\n"
     ]
    }
   ],
   "source": [
    "word = \"language\"\n",
    "similar_words = model.wv.most_similar(word)\n",
    "print(f\"Words similar to  {word}:\\n {similar_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9edbfe7",
   "metadata": {},
   "source": [
    "let's save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd288310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0f7fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(os.getcwd(), \"models\",\"word2vec.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b939326",
   "metadata": {},
   "source": [
    "let's load the saved model and use to find similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c8c5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = Word2Vec.load(os.path.join(os.getcwd(), \"models\",\"word2vec.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ab1a750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to  language:\n",
      " [('the', 0.21926084160804749), ('applications', 0.21701940894126892), ('many', 0.20485423505306244), ('bots', 0.19553223252296448), ('you', 0.17234398424625397), ('complex', 0.17025862634181976), ('generally', 0.1519763022661209), ('study', 0.14263521134853363), ('voice', 0.14103567600250244), ('systems', 0.14074334502220154)]\n"
     ]
    }
   ],
   "source": [
    "word = \"language\"\n",
    "similar_words = loaded_model.wv.most_similar(word)\n",
    "print(f\"Words similar to  {word}:\\n {similar_words}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_gensim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
