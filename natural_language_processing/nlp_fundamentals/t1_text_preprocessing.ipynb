{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ca4f6a",
   "metadata": {},
   "source": [
    "### Text Normalization/Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7592569",
   "metadata": {},
   "source": [
    "Text preprocessing is the process to clean the text before any model execution. There are several operations which we can perform to clean the data, such as :\n",
    "\n",
    "1. Stemming\n",
    "2. Lemmatization\n",
    "3. StopWords\n",
    "\n",
    "There are several libraries to achieve this process. Here we will be using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04c00d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Major tasks in natural language processing are speech recognition, text classification, natural language understanding, and natural language generation.\"\n",
    "textList = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6006d44b",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "The process of reduce words to their root or base form. Stemming uses rule based approach to do the conversion which does not certain the valid word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb2973d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eef279cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cc8f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grow'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample stemming\n",
    "ps.stem(\"growing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28579355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happili'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"happily\") # there is no word -> happili ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf79cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do it for our text \n",
    "stemText = [ps.stem(item) for item in textList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f25342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natur\n",
      "languag\n",
      "process\n",
      "(nlp)\n",
      "comput\n",
      "scienc\n",
      "especi\n",
      "artifici\n",
      "it\n",
      "primarili\n",
      "concern\n",
      "provid\n",
      "comput\n",
      "abil\n",
      "encod\n",
      "natur\n",
      "languag\n",
      "thu\n",
      "close\n",
      "relat\n",
      "inform\n",
      "knowledg\n",
      "represent\n",
      "comput\n",
      "major\n",
      "task\n",
      "natur\n",
      "languag\n",
      "process\n",
      "natur\n",
      "languag\n",
      "natur\n",
      "languag\n"
     ]
    }
   ],
   "source": [
    "# let's see the difference\n",
    "for i in range(len(textList)):\n",
    "    if textList[i] != stemText[i]:\n",
    "        print( stemText[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d17da",
   "metadata": {},
   "source": [
    "here we saw, lots of words that got stemmed on the basis of PorterStemmer algo. Some words are not event correct. So we have to use thi wisely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50420943",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "The process to reduce words to their base or dictionary form, known as the lemma. It uses data source and returns valid dictionary word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f03728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83ce14",
   "metadata": {},
   "source": [
    "Before utilizing the lemmatization, we must download the resources first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d121f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bumblebee\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e846a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the object for lemmatizer class\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e3ed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample lemmatize\n",
    "wnl.lemmatize(\"lives\") # should give life\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f56fa263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do this for the given text and see the result\n",
    "lemmatizeText = [wnl.lemmatize(item) for item in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer\n",
      "task\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(textList)):\n",
    "    if textList[i] != lemmatizeText[i]:\n",
    "        print(lemmatizeText[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b0514",
   "metadata": {},
   "source": [
    "now here we could see two words have been lemmatize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9e794",
   "metadata": {},
   "source": [
    "#### StopWords\n",
    "Common words in a sentence which does not add a significant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69e8ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7ae97",
   "metadata": {},
   "source": [
    "before using it, we must download it's sourced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fba78c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bumblebee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "767f6307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see few stopwords, in english\n",
    "stopwords.words(\"english\")[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d5449",
   "metadata": {},
   "source": [
    "stopwords are also available in other languages, such as German, Indonesian, Portuguese, and Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6c4de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's apply stop words in are text\n",
    "stopwordsText = [ item for item in textList if item not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "839df10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(NLP)',\n",
       " 'subfield',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'especially',\n",
       " 'artificial',\n",
       " 'intelligence.',\n",
       " 'It',\n",
       " 'primarily',\n",
       " 'concerned',\n",
       " 'providing',\n",
       " 'computers',\n",
       " 'ability',\n",
       " 'process',\n",
       " 'data',\n",
       " 'encoded',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'thus',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'information',\n",
       " 'retrieval,',\n",
       " 'knowledge',\n",
       " 'representation',\n",
       " 'computational',\n",
       " 'linguistics,',\n",
       " 'subfield',\n",
       " 'linguistics.',\n",
       " 'Major',\n",
       " 'tasks',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'speech',\n",
       " 'recognition,',\n",
       " 'text',\n",
       " 'classification,',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'understanding,',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'generation.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwordsText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5c4dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'and', 'are', 'in', 'is', 'of', 'the', 'to', 'with'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  let's see the removed words\n",
    "\n",
    "set(textList) - set(stopwordsText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ac3cb",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "The process of breaking down the long text into a unit. A unit could a word, char or a even a sentence too, which is called a token.\n",
    "\n",
    "1. Word tokenization: Splits text into individual words. \n",
    "2. Sentence tokenization: Splits text into individual sentences. \n",
    "3. Character tokenization: Splits text into individual characters. \n",
    "4. Subword tokenization: Splits text into meaningful sub-word units, like byte-pair encoding (BPE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f623d225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(NLP)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'especially',\n",
       " 'artificial',\n",
       " 'intelligence.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'primarily',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'providing',\n",
       " 'computers',\n",
       " 'with',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'process',\n",
       " 'data',\n",
       " 'encoded',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'and',\n",
       " 'is',\n",
       " 'thus',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'to',\n",
       " 'information',\n",
       " 'retrieval,',\n",
       " 'knowledge',\n",
       " 'representation',\n",
       " 'and',\n",
       " 'computational',\n",
       " 'linguistics,',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics.',\n",
       " 'Major',\n",
       " 'tasks',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'are',\n",
       " 'speech',\n",
       " 'recognition,',\n",
       " 'text',\n",
       " 'classification,',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'understanding,',\n",
       " 'and',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'generation.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordTokens = text.split()\n",
    "wordTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe4239",
   "metadata": {},
   "source": [
    "#### Other techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b50f2",
   "metadata": {},
   "source": [
    "There could be various mechanism to preprocess or normalize the text. It depends upon the use case to use case, like which one has to choose or works good. Other techniques can be like:\n",
    "\n",
    "1. Replacing text with regex pattern\n",
    "2. Removal of unwanted text\n",
    "3. Removal of punctuations\n",
    "4. Changing the case of the text etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26ba8c",
   "metadata": {},
   "source": [
    "##### Removal of Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "025b2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "989287c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuationFreeText = [item for item in textList if item not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "288e8667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Major tasks in natural language processing are speech recognition, text classification, natural language understanding, and natural language generation.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(punctuationFreeText)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
